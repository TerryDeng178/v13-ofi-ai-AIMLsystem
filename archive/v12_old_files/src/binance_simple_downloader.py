#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸å®‰ç®€å•æ•°æ®ä¸‹è½½å™¨
åŸºäºå®˜æ–¹æ–‡æ¡£çš„ç®€åŒ–ç‰ˆæœ¬
"""

import os
import time
import requests
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BinanceSimpleDownloader:
    """å¸å®‰ç®€å•æ•°æ®ä¸‹è½½å™¨"""
    
    def __init__(self, base_url="https://fapi.binance.com"):
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # åˆ›å»ºæ•°æ®ç›®å½•
        os.makedirs("data/binance", exist_ok=True)
        
        logger.info("å¸å®‰ç®€å•ä¸‹è½½å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def fetch_klines(self, symbol: str, interval: str, limit: int = 1000) -> pd.DataFrame:
        """
        è·å–Kçº¿æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å· (å¦‚: "ETHUSDT")
            interval: Kçº¿å‘¨æœŸ (å¦‚: "1m", "5m", "1h")
            limit: è·å–æ ¹æ•° (æœ€å¤§1000)
            
        Returns:
            åŒ…å«Kçº¿æ•°æ®çš„DataFrame
        """
        url = f"{self.base_url}/fapi/v1/klines"
        params = {
            "symbol": symbol,
            "interval": interval,
            "limit": min(limit, 1000)  # å¸å®‰APIé™åˆ¶
        }
        
        try:
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data, columns=[
                'open_time', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
            ])
            
            # æ•°æ®ç±»å‹è½¬æ¢
            df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')
            df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')
            
            numeric_columns = ['open', 'high', 'low', 'close', 'volume', 
                              'quote_asset_volume', 'taker_buy_base_asset_volume', 
                              'taker_buy_quote_asset_volume']
            for col in numeric_columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            df['number_of_trades'] = pd.to_numeric(df['number_of_trades'], errors='coerce')
            
            return df
            
        except Exception as e:
            logger.error(f"è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def download_klines_6months(self, symbol: str, interval: str) -> pd.DataFrame:
        """
        ä¸‹è½½6ä¸ªæœˆKçº¿æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            interval: Kçº¿å‘¨æœŸ
        """
        logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½ {symbol} {interval} 6ä¸ªæœˆKçº¿æ•°æ®...")
        
        all_data = []
        end_time = datetime.now()
        start_time = end_time - timedelta(days=180)
        
        current_time = start_time
        batch_count = 0
        
        while current_time < end_time:
            try:
                # è·å–æ•°æ®
                df = self.fetch_klines(symbol, interval, 1000)
                
                if df.empty:
                    logger.info("âš ï¸ æ²¡æœ‰æ›´å¤šæ•°æ®ï¼Œä¸‹è½½å®Œæˆ")
                    break
                
                all_data.append(df)
                batch_count += 1
                current_time = df['close_time'].max()
                
                logger.info(f"ğŸ“Š æ‰¹æ¬¡ {batch_count}: {len(df)} æ¡æ•°æ®, æœ€æ–°æ—¶é—´: {current_time}")
                
                # APIé™åˆ¶ä¿æŠ¤
                time.sleep(0.1)
                
            except Exception as e:
                logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
                time.sleep(1)
                continue
        
        if all_data:
            # åˆå¹¶æ•°æ®
            final_df = pd.concat(all_data, ignore_index=True)
            final_df = final_df.drop_duplicates(subset=['open_time']).sort_values('open_time')
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…V11ç³»ç»Ÿ
            final_df = final_df.rename(columns={
                'open_time': 'timestamp',
                'open': 'open',
                'high': 'high',
                'low': 'low',
                'close': 'close',
                'volume': 'volume'
            })
            
            # é€‰æ‹©éœ€è¦çš„åˆ—
            final_df = final_df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]
            
            # ä¿å­˜æ•°æ®
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            cache_file = f"data/binance/{symbol}_{interval}_6months_{timestamp}.csv"
            final_df.to_csv(cache_file, index=False)
            
            logger.info(f"âœ… Kçº¿æ•°æ®ä¸‹è½½å®Œæˆ: {len(final_df)} æ¡è®°å½•")
            logger.info(f"ğŸ“ ä¿å­˜ä½ç½®: {cache_file}")
            logger.info(f"ğŸ“… æ—¶é—´èŒƒå›´: {final_df['timestamp'].min()} ~ {final_df['timestamp'].max()}")
            
            return final_df
        else:
            logger.error("âŒ æ²¡æœ‰ä¸‹è½½åˆ°ä»»ä½•æ•°æ®")
            return pd.DataFrame()
    
    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥"""
        try:
            url = f"{self.base_url}/fapi/v1/ping"
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            logger.info("âœ… å¸å®‰APIè¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ å¸å®‰APIè¿æ¥å¤±è´¥: {e}")
            return False


def download_ethusdt_6months():
    """ä¸‹è½½ETHUSDT 6ä¸ªæœˆæ•°æ®"""
    logger.info("=" * 80)
    logger.info("å¸å®‰ETHUSDT 6ä¸ªæœˆæ•°æ®ä¸‹è½½")
    logger.info("=" * 80)
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = BinanceSimpleDownloader()
    
    # æµ‹è¯•è¿æ¥
    if not downloader.test_connection():
        logger.error("è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ")
        return False
    
    # ä¸‹è½½ETHUSDT 1åˆ†é’Ÿæ•°æ®
    logger.info("å¼€å§‹ä¸‹è½½ETHUSDT 1åˆ†é’ŸKçº¿æ•°æ®...")
    df = downloader.download_klines_6months("ETHUSDT", "1m")
    
    if not df.empty:
        logger.info("=" * 60)
        logger.info("æ•°æ®è´¨é‡æŠ¥å‘Š")
        logger.info("=" * 60)
        logger.info(f"è®°å½•æ•°: {len(df):,}")
        logger.info(f"æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        logger.info(f"ä»·æ ¼èŒƒå›´: {df['close'].min():.2f} ~ {df['close'].max():.2f}")
        logger.info(f"å¹³å‡æˆäº¤é‡: {df['volume'].mean():,.0f}")
        logger.info(f"ç¼ºå¤±å€¼: {df.isnull().sum().sum()}")
        logger.info(f"é‡å¤å€¼: {df.duplicated().sum()}")
        
        logger.info("=" * 80)
        logger.info("ğŸ‰ ETHUSDT 6ä¸ªæœˆæ•°æ®ä¸‹è½½å®Œæˆï¼")
        logger.info("ç°åœ¨å¯ä»¥å¼€å§‹V11è®­ç»ƒäº†ã€‚")
        logger.info("=" * 80)
        
        return True
    else:
        logger.error("âŒ æ•°æ®ä¸‹è½½å¤±è´¥")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("å¸å®‰ç®€å•æ•°æ®ä¸‹è½½å™¨")
    logger.info("=" * 80)
    
    download_ethusdt_6months()


if __name__ == "__main__":
    main()
