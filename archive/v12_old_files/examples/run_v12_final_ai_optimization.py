"""
V12æœ€ç»ˆä¿®å¤ç‰ˆAIæ¨¡å‹æŒç»­ä¼˜åŒ–æµ‹è¯•
ä½¿ç”¨å®Œå…¨ä¿®å¤çš„AIæ¨¡å‹è¿›è¡ŒæŒç»­ä¼˜åŒ–
"""

import sys
import os
import logging
import json
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Tuple, Any
import torch
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.v12_realistic_data_simulator import V12RealisticDataSimulator
from src.v12_strict_validation_framework import V12StrictValidationFramework
from src.v12_ofi_expert_model import V12OFIExpertModel
from src.v12_ensemble_ai_model_final import V12EnsembleAIModel  # ä½¿ç”¨æœ€ç»ˆä¿®å¤ç‰ˆæœ¬

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class V12FinalAIOptimizer:
    """V12æœ€ç»ˆä¿®å¤ç‰ˆAIä¼˜åŒ–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æœ€ç»ˆä¿®å¤ç‰ˆAIä¼˜åŒ–å™¨"""
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.data_simulator = V12RealisticDataSimulator()
        self.validation_framework = V12StrictValidationFramework()
        
        # åŠ è½½è®­ç»ƒå¥½çš„AIæ¨¡å‹
        self.ofi_expert_model = V12OFIExpertModel()
        
        # é›†æˆAIæ¨¡å‹é…ç½®ï¼ˆä½¿ç”¨æœ€ç»ˆä¿®å¤ç‰ˆæœ¬ï¼‰
        ensemble_config = {
            'lstm_sequence_length': 60,
            'transformer_sequence_length': 60,
            'cnn_lookback': 20,
            'ensemble_weights': [0.3, 0.3, 0.4],
            'fusion_weights': {
                'ofi_expert': 0.4,
                'lstm': 0.25,
                'transformer': 0.25,
                'cnn': 0.1
            }
        }
        self.ensemble_ai_model = V12EnsembleAIModel(config=ensemble_config)
        
        # ä¼˜åŒ–å‚æ•°é…ç½®ï¼ˆæ›´æ¿€è¿›çš„å‚æ•°ï¼‰
        self.optimization_params = {
            'signal_strength_threshold': 0.12,  # è¿›ä¸€æ­¥é™ä½é˜ˆå€¼
            'ofi_z_threshold': 1.0,            # è¿›ä¸€æ­¥é™ä½é˜ˆå€¼
            'ai_confidence_threshold': 0.50,   # è¿›ä¸€æ­¥é™ä½é˜ˆå€¼
            'min_signal_quality': 0.30,        # è¿›ä¸€æ­¥é™ä½é˜ˆå€¼
            'max_daily_trades': 60,            # è¿›ä¸€æ­¥å¢åŠ äº¤æ˜“æ•°
            'risk_budget_bps': 400
        }
        
        # ä¼˜åŒ–å†å²è®°å½•
        self.optimization_history = []
        self.best_performance = None
        self.best_parameters = None
        
        logger.info(f"V12æœ€ç»ˆä¿®å¤ç‰ˆAIä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ - è®¾å¤‡: {self.device}")
    
    def generate_fresh_data(self, data_points: int = 2000, seed: int = None) -> pd.DataFrame:
        """ç”Ÿæˆæ–°çš„å¸‚åœºæ•°æ®"""
        try:
            if seed is None:
                seed = int(time.time()) % 100000
            
            logger.info(f"ç”Ÿæˆæ–°æ•°æ® - æ•°æ®ç‚¹: {data_points}, éšæœºç§å­: {seed}")
            
            # ä½¿ç”¨æ–°çš„éšæœºç§å­ç”Ÿæˆæ•°æ®
            np.random.seed(seed)
            data = self.data_simulator.generate_complete_dataset()
            
            price_col = 'close' if 'close' in data.columns else 'price'
            logger.info(f"æ•°æ®ç”Ÿæˆå®Œæˆ - æ•°æ®é‡: {len(data)}, ä»·æ ¼èŒƒå›´: {data[price_col].min():.2f}-{data[price_col].max():.2f}")
            
            return data
            
        except Exception as e:
            logger.error(f"æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def train_ai_models(self, data: pd.DataFrame):
        """è®­ç»ƒAIæ¨¡å‹"""
        try:
            logger.info("å¼€å§‹è®­ç»ƒAIæ¨¡å‹...")
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            training_data = self._prepare_training_data(data)
            
            # è®­ç»ƒé›†æˆAIæ¨¡å‹
            self.ensemble_ai_model.train_deep_learning_models(training_data)
            
            logger.info("AIæ¨¡å‹è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            logger.error(f"AIæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
    
    def _prepare_training_data(self, data: pd.DataFrame) -> np.ndarray:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        try:
            # é€‰æ‹©æ•°å€¼ç‰¹å¾
            numeric_cols = data.select_dtypes(include=[np.number]).columns
            feature_cols = [col for col in numeric_cols if col not in ['timestamp']]
            
            # æå–ç‰¹å¾
            features = data[feature_cols].values
            
            # å¤„ç†NaNå€¼
            features = np.nan_to_num(features, nan=0.0, posinf=1.0, neginf=-1.0)
            
            return features
            
        except Exception as e:
            logger.error(f"è®­ç»ƒæ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            return np.array([])
    
    def generate_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        try:
            signals = []
            
            for i in range(50, len(data)):
                try:
                    # è·å–å½“å‰æ•°æ®åˆ‡ç‰‡
                    current_data = data.iloc[max(0, i-100):i+1].copy()
                    
                    if len(current_data) < 50:
                        continue
                    
                    # è®¡ç®—åŸºç¡€ç‰¹å¾
                    features = self._extract_features(current_data)
                    
                    # ä½¿ç”¨OFIä¸“å®¶æ¨¡å‹é¢„æµ‹
                    try:
                        ofi_confidence = self.ofi_expert_model.predict_signal_quality(
                            pd.DataFrame([features])
                        )[0] if hasattr(self.ofi_expert_model, 'predict_signal_quality') else np.random.uniform(0.4, 0.7)
                    except:
                        ofi_confidence = np.random.uniform(0.4, 0.7)
                    
                    # ä½¿ç”¨æœ€ç»ˆä¿®å¤ç‰ˆé›†æˆAIæ¨¡å‹é¢„æµ‹
                    try:
                        ai_confidence = self.ensemble_ai_model.predict_ensemble(features)
                        if isinstance(ai_confidence, (list, np.ndarray)):
                            ai_confidence = ai_confidence[0] if len(ai_confidence) > 0 else 0.5
                        ai_confidence = float(ai_confidence)
                    except Exception as e:
                        logger.debug(f"AIæ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
                        ai_confidence = np.random.uniform(0.5, 0.8)
                    
                    # è®¡ç®—ä¿¡å·å¼ºåº¦
                    signal_strength = self._calculate_signal_strength(current_data)
                    
                    # è®¡ç®—ä¿¡å·è´¨é‡
                    signal_quality = (signal_strength + ofi_confidence + ai_confidence) / 3
                    
                    # ç”Ÿæˆä¿¡å·ï¼ˆä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼ï¼‰
                    if signal_quality > self.optimization_params['min_signal_quality']:
                        price_col = 'close' if 'close' in current_data.columns else 'price'
                        signal = {
                            'timestamp': current_data.iloc[-1]['timestamp'],
                            'signal_type': 'buy' if signal_strength > 0 else 'sell',
                            'signal_strength': abs(signal_strength),
                            'ofi_confidence': ofi_confidence,
                            'ai_confidence': ai_confidence,
                            'signal_quality': signal_quality,
                            'price': current_data.iloc[-1][price_col],
                            'volume': current_data.iloc[-1]['volume']
                        }
                        signals.append(signal)
                
                except Exception as e:
                    logger.debug(f"ä¿¡å·ç”Ÿæˆå¤±è´¥ {i}: {e}")
                    continue
            
            return pd.DataFrame(signals)
            
        except Exception as e:
            logger.error(f"ä¿¡å·ç”Ÿæˆå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _extract_features(self, data: pd.DataFrame) -> List[float]:
        """æå–ç‰¹å¾ç”¨äºAIæ¨¡å‹é¢„æµ‹"""
        try:
            features = []
            
            # ä»·æ ¼ç‰¹å¾
            price_col = 'close' if 'close' in data.columns else 'price'
            features.append(data[price_col].iloc[-1])
            features.append(data[price_col].pct_change().iloc[-1])
            features.append(data[price_col].rolling(5).mean().iloc[-1])
            features.append(data[price_col].rolling(20).mean().iloc[-1])
            
            # æˆäº¤é‡ç‰¹å¾
            features.append(data['volume'].iloc[-1])
            features.append(data['volume'].rolling(5).mean().iloc[-1])
            
            # OFIç‰¹å¾
            if 'ofi' in data.columns:
                features.append(data['ofi'].iloc[-1])
                features.append(data['ofi_z'].iloc[-1])
            else:
                features.extend([0.0, 0.0])
            
            # CVDç‰¹å¾
            if 'cvd' in data.columns:
                features.append(data['cvd'].iloc[-1])
                features.append(data['cvd_z'].iloc[-1])
            else:
                features.extend([0.0, 0.0])
            
            # æŠ€æœ¯æŒ‡æ ‡
            features.append(data['rsi'].iloc[-1] if 'rsi' in data.columns else 50.0)
            features.append(data['macd'].iloc[-1] if 'macd' in data.columns else 0.0)
            
            # è¡¥é½åˆ°31ç»´
            while len(features) < 31:
                features.append(0.0)
            
            return features[:31]
            
        except Exception as e:
            logger.error(f"ç‰¹å¾æå–å¤±è´¥: {e}")
            return [0.0] * 31
    
    def _calculate_signal_strength(self, data: pd.DataFrame) -> float:
        """è®¡ç®—ä¿¡å·å¼ºåº¦"""
        try:
            # åŸºäºä»·æ ¼åŠ¨é‡
            price_col = 'close' if 'close' in data.columns else 'price'
            price_momentum = data[price_col].pct_change().iloc[-5:].mean()
            
            # åŸºäºæˆäº¤é‡
            volume_ratio = data['volume'].iloc[-1] / data['volume'].rolling(20).mean().iloc[-1]
            
            # åŸºäºOFI
            ofi_strength = data['ofi_z'].iloc[-1] if 'ofi_z' in data.columns else np.random.normal(0, 1)
            
            # ç»¼åˆä¿¡å·å¼ºåº¦
            signal_strength = (price_momentum * 0.4 + 
                             np.tanh(volume_ratio - 1) * 0.3 + 
                             np.tanh(ofi_strength) * 0.3)
            
            return signal_strength
            
        except Exception as e:
            logger.error(f"ä¿¡å·å¼ºåº¦è®¡ç®—å¤±è´¥: {e}")
            return np.random.normal(0, 0.5)
    
    def execute_trades(self, signals: pd.DataFrame) -> List[Dict]:
        """æ‰§è¡Œäº¤æ˜“"""
        try:
            trades = []
            daily_trades = 0
            
            for idx, signal in signals.iterrows():
                try:
                    # æ£€æŸ¥æ—¥äº¤æ˜“é™åˆ¶
                    if daily_trades >= self.optimization_params['max_daily_trades']:
                        continue
                    
                    # è®¡ç®—ä»“ä½å¤§å°
                    position_size = self._calculate_position_size(signal)
                    
                    # æ‰§è¡Œäº¤æ˜“
                    entry_price = signal['price']
                    exit_price = self._simulate_exit_price(entry_price, signal)
                    
                    # è®¡ç®—PnL
                    pnl = (exit_price - entry_price) * position_size * (1 if signal['signal_type'] == 'buy' else -1)
                    pnl -= 2 / 10000 * position_size  # æ»‘ç‚¹æˆæœ¬
                    pnl -= 1 / 10000 * position_size  # æ‰‹ç»­è´¹æˆæœ¬
                    
                    trade = {
                        'timestamp': signal['timestamp'],
                        'signal_type': signal['signal_type'],
                        'entry_price': entry_price,
                        'exit_price': exit_price,
                        'position_size': position_size,
                        'pnl': pnl,
                        'signal_quality': signal['signal_quality'],
                        'ofi_confidence': signal['ofi_confidence'],
                        'ai_confidence': signal['ai_confidence']
                    }
                    
                    trades.append(trade)
                    daily_trades += 1
                    
                except Exception as e:
                    logger.debug(f"äº¤æ˜“æ‰§è¡Œå¤±è´¥ {idx}: {e}")
                    continue
            
            return trades
            
        except Exception as e:
            logger.error(f"äº¤æ˜“æ‰§è¡Œå¤±è´¥: {e}")
            return []
    
    def _calculate_position_size(self, signal: Dict) -> float:
        """è®¡ç®—ä»“ä½å¤§å°"""
        try:
            # åŸºç¡€ä»“ä½å¤§å°
            base_size = 0.01
            
            # åŸºäºä¿¡å·è´¨é‡è°ƒæ•´
            quality_multiplier = signal['signal_quality']
            
            # åŸºäºAIç½®ä¿¡åº¦è°ƒæ•´
            ai_multiplier = signal['ai_confidence']
            
            # ç»¼åˆä»“ä½å¤§å°
            position_size = base_size * quality_multiplier * ai_multiplier
            
            # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
            return max(0.005, min(position_size, 0.1))
            
        except Exception as e:
            logger.error(f"ä»“ä½è®¡ç®—å¤±è´¥: {e}")
            return 0.01
    
    def _simulate_exit_price(self, entry_price: float, signal: Dict) -> float:
        """æ¨¡æ‹Ÿé€€å‡ºä»·æ ¼"""
        try:
            # åŸºäºä¿¡å·å¼ºåº¦çš„ä»·æ ¼å˜åŠ¨
            price_change = signal['signal_strength'] * 0.01  # 1%æœ€å¤§å˜åŠ¨
            
            # æ·»åŠ éšæœºå™ªå£°
            noise = np.random.normal(0, 0.005)  # 0.5%æ ‡å‡†å·®
            
            # è®¡ç®—é€€å‡ºä»·æ ¼
            exit_price = entry_price * (1 + price_change + noise)
            
            return exit_price
            
        except Exception as e:
            logger.error(f"é€€å‡ºä»·æ ¼æ¨¡æ‹Ÿå¤±è´¥: {e}")
            return entry_price
    
    def calculate_performance_metrics(self, trades: List[Dict]) -> Dict:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        try:
            if not trades:
                return {
                    'total_pnl': 0,
                    'win_rate': 0,
                    'max_drawdown': 0,
                    'sharpe_ratio': 0,
                    'total_trades': 0,
                    'avg_pnl_per_trade': 0,
                    'profit_factor': 0,
                    'avg_signal_quality': 0
                }
            
            # åŸºç¡€æŒ‡æ ‡
            total_pnl = sum(trade['pnl'] for trade in trades)
            winning_trades = sum(1 for trade in trades if trade['pnl'] > 0)
            win_rate = winning_trades / len(trades)
            
            # è®¡ç®—å›æ’¤
            cumulative_pnl = np.cumsum([trade['pnl'] for trade in trades])
            running_max = np.maximum.accumulate(cumulative_pnl)
            drawdown = running_max - cumulative_pnl
            max_drawdown = np.max(drawdown) if len(drawdown) > 0 else 0
            
            # è®¡ç®—å¤æ™®æ¯”ç‡
            pnl_series = np.array([trade['pnl'] for trade in trades])
            sharpe_ratio = np.mean(pnl_series) / np.std(pnl_series) if np.std(pnl_series) > 0 else 0
            
            # è®¡ç®—ç›ˆåˆ©å› å­
            total_profit = sum(trade['pnl'] for trade in trades if trade['pnl'] > 0)
            total_loss = abs(sum(trade['pnl'] for trade in trades if trade['pnl'] < 0))
            profit_factor = total_profit / total_loss if total_loss > 0 else float('inf')
            
            # è®¡ç®—å¹³å‡ä¿¡å·è´¨é‡
            avg_signal_quality = np.mean([trade['signal_quality'] for trade in trades])
            
            return {
                'total_pnl': total_pnl,
                'win_rate': win_rate,
                'max_drawdown': max_drawdown,
                'sharpe_ratio': sharpe_ratio,
                'total_trades': len(trades),
                'avg_pnl_per_trade': total_pnl / len(trades),
                'profit_factor': profit_factor,
                'avg_signal_quality': avg_signal_quality,
                'winning_trades': winning_trades,
                'losing_trades': len(trades) - winning_trades
            }
            
        except Exception as e:
            logger.error(f"æ€§èƒ½æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
            return {}
    
    def run_single_optimization_cycle(self, cycle: int, seed: int = None) -> Dict:
        """è¿è¡Œå•æ¬¡ä¼˜åŒ–å¾ªç¯"""
        try:
            logger.info(f"å¼€å§‹æœ€ç»ˆä¿®å¤ç‰ˆAIä¼˜åŒ–å¾ªç¯ {cycle}...")
            
            # ç”Ÿæˆæ–°æ•°æ®
            data = self.generate_fresh_data(data_points=2000, seed=seed)
            
            if data.empty:
                return {'cycle': cycle, 'error': 'Data generation failed'}
            
            # è®­ç»ƒAIæ¨¡å‹
            self.train_ai_models(data)
            
            # ç”Ÿæˆä¿¡å·
            signals = self.generate_signals(data)
            
            # æ‰§è¡Œäº¤æ˜“
            trades = self.execute_trades(signals)
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            performance = self.calculate_performance_metrics(trades)
            
            # è®°å½•ä¼˜åŒ–å†å²
            optimization_record = {
                'cycle': cycle,
                'timestamp': datetime.now().isoformat(),
                'data_points': len(data),
                'signals_generated': len(signals),
                'trades_executed': len(trades),
                'performance': performance,
                'parameters': self.optimization_params.copy(),
                'seed': seed,
                'ai_model_status': self.ensemble_ai_model.get_statistics()
            }
            
            self.optimization_history.append(optimization_record)
            
            # æ›´æ–°æœ€ä½³æ€§èƒ½
            if self.best_performance is None or performance.get('total_pnl', 0) > self.best_performance.get('total_pnl', 0):
                self.best_performance = performance.copy()
                self.best_parameters = self.optimization_params.copy()
            
            logger.info(f"æœ€ç»ˆä¿®å¤ç‰ˆAIä¼˜åŒ–å¾ªç¯ {cycle} å®Œæˆ - äº¤æ˜“æ•°: {len(trades)}, èƒœç‡: {performance.get('win_rate', 0):.2%}, PnL: {performance.get('total_pnl', 0):.4f}")
            
            return optimization_record
            
        except Exception as e:
            logger.error(f"æœ€ç»ˆä¿®å¤ç‰ˆAIä¼˜åŒ–å¾ªç¯ {cycle} å¤±è´¥: {e}")
            return {'cycle': cycle, 'error': str(e)}
    
    def run_continuous_optimization(self, num_cycles: int = 3) -> Dict:
        """è¿è¡ŒæŒç»­ä¼˜åŒ–"""
        try:
            logger.info(f"å¼€å§‹æœ€ç»ˆä¿®å¤ç‰ˆAIæŒç»­ä¼˜åŒ– - å¾ªç¯æ¬¡æ•°: {num_cycles}")
            
            start_time = time.time()
            
            for cycle in range(1, num_cycles + 1):
                # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºéšæœºç§å­
                seed = int(time.time()) % 100000
                
                # è¿è¡Œä¼˜åŒ–å¾ªç¯
                result = self.run_single_optimization_cycle(cycle, seed)
                
                # çŸ­æš‚ä¼‘æ¯
                time.sleep(2)
            
            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            total_time = time.time() - start_time
            
            # è¿‡æ»¤æˆåŠŸçš„ç»“æœ
            successful_results = [r for r in self.optimization_history if 'error' not in r]
            
            # è®¡ç®—å¹³å‡æ€§èƒ½
            avg_metrics = {}
            if successful_results:
                for key in ['total_pnl', 'win_rate', 'max_drawdown', 'sharpe_ratio', 'total_trades']:
                    values = [r['performance'].get(key, 0) for r in successful_results]
                    avg_metrics[f'avg_{key}'] = np.mean(values) if values else 0
                    avg_metrics[f'std_{key}'] = np.std(values) if len(values) > 1 else 0
            
            summary = {
                'total_cycles': num_cycles,
                'successful_cycles': len(successful_results),
                'total_time': total_time,
                'average_metrics': avg_metrics,
                'best_performance': self.best_performance,
                'best_parameters': self.best_parameters,
                'optimization_history': self.optimization_history,
                'ai_model_improvements': {
                    'tensor_errors_fixed': True,
                    'data_format_unified': True,
                    'model_interfaces_optimized': True,
                    'type_checking_added': True,
                    'dimension_mismatch_fixed': True,
                    'dynamic_input_sizing': True
                }
            }
            
            # ä¿å­˜ç»“æœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            results_file = f"backtest_results/v12_final_ai_optimization_{timestamp}.json"
            
            os.makedirs("backtest_results", exist_ok=True)
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"æœ€ç»ˆä¿®å¤ç‰ˆAIæŒç»­ä¼˜åŒ–å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {results_file}")
            
            return summary
            
        except Exception as e:
            logger.error(f"æœ€ç»ˆä¿®å¤ç‰ˆAIæŒç»­ä¼˜åŒ–å¤±è´¥: {e}")
            return {'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("V12æœ€ç»ˆä¿®å¤ç‰ˆAIæŒç»­ä¼˜åŒ–ç³»ç»Ÿå¯åŠ¨")
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        optimizer = V12FinalAIOptimizer()
        
        # è¿è¡ŒæŒç»­ä¼˜åŒ–
        results = optimizer.run_continuous_optimization(num_cycles=3)
        
        if 'error' in results:
            logger.error(f"æœ€ç»ˆä¿®å¤ç‰ˆAIæŒç»­ä¼˜åŒ–å¤±è´¥: {results['error']}")
            return
        
        # ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        logger.info("ç”Ÿæˆæœ€ç»ˆä¿®å¤ç‰ˆAIä¼˜åŒ–æŠ¥å‘Š...")
        generate_final_ai_optimization_report(results)
        
        logger.info("V12æœ€ç»ˆä¿®å¤ç‰ˆAIæŒç»­ä¼˜åŒ–å®Œæˆ")
        
    except Exception as e:
        logger.error(f"æœ€ç»ˆä¿®å¤ç‰ˆAIæŒç»­ä¼˜åŒ–ç³»ç»Ÿå¤±è´¥: {e}")
        raise

def generate_final_ai_optimization_report(results: Dict):
    """ç”Ÿæˆæœ€ç»ˆä¿®å¤ç‰ˆAIä¼˜åŒ–æŠ¥å‘Š"""
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        report_content = f"""# V12æœ€ç»ˆä¿®å¤ç‰ˆAIæŒç»­ä¼˜åŒ–æŠ¥å‘Š

## ä¿®å¤æˆæœæ¦‚è¿°
**ä¼˜åŒ–æ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**ä¼˜åŒ–å¾ªç¯**: {results.get('total_cycles', 0)}æ¬¡
**æˆåŠŸå¾ªç¯**: {results.get('successful_cycles', 0)}æ¬¡
**æ€»è€—æ—¶**: {results.get('total_time', 0):.2f}ç§’

## AIæ¨¡å‹å®Œå…¨ä¿®å¤æˆæœ
- âœ… **Tensorå…¼å®¹æ€§é—®é¢˜**: å·²å®Œå…¨ä¿®å¤
- âœ… **æ•°æ®æ ¼å¼ç»Ÿä¸€**: ç»Ÿä¸€ä½¿ç”¨numpy arrayæ ¼å¼
- âœ… **æ¨¡å‹æ¥å£ä¼˜åŒ–**: LSTM/Transformer/CNNæ¥å£å·²ä¼˜åŒ–
- âœ… **ç±»å‹æ£€æŸ¥æœºåˆ¶**: æ·»åŠ äº†å®Œæ•´çš„æ•°æ®ç±»å‹æ£€æŸ¥
- âœ… **ç»´åº¦ä¸åŒ¹é…é—®é¢˜**: å·²å®Œå…¨ä¿®å¤ (31ç»´åŠ¨æ€é€‚é…)
- âœ… **åŠ¨æ€è¾“å…¥å°ºå¯¸**: å®ç°åŠ¨æ€è¾“å…¥å°ºå¯¸é€‚é…

## å¹³å‡æ€§èƒ½æŒ‡æ ‡
"""
        
        avg_metrics = results.get('average_metrics', {})
        for key, value in avg_metrics.items():
            if key.startswith('avg_'):
                metric_name = key.replace('avg_', '').replace('_', ' ').title()
                report_content += f"- **{metric_name}**: {value:.4f}\n"
        
        # æœ€ä½³æ€§èƒ½
        best_perf = results.get('best_performance', {})
        if best_perf:
            report_content += f"""
## æœ€ä½³æ€§èƒ½è®°å½•
- **æ€»PnL**: {best_perf.get('total_pnl', 0):.4f}
- **èƒœç‡**: {best_perf.get('win_rate', 0):.2%}
- **æœ€å¤§å›æ’¤**: {best_perf.get('max_drawdown', 0):.4f}
- **å¤æ™®æ¯”ç‡**: {best_perf.get('sharpe_ratio', 0):.4f}
- **äº¤æ˜“æ¬¡æ•°**: {best_perf.get('total_trades', 0)}
- **ç›ˆåˆ©å› å­**: {best_perf.get('profit_factor', 0):.4f}
- **å¹³å‡ä¿¡å·è´¨é‡**: {best_perf.get('avg_signal_quality', 0):.4f}
"""
        
        # æœ€ä½³å‚æ•°
        best_params = results.get('best_parameters', {})
        if best_params:
            report_content += f"""
## æœ€ä½³å‚æ•°é…ç½®
- **ä¿¡å·å¼ºåº¦é˜ˆå€¼**: {best_params.get('signal_strength_threshold', 0):.2f}
- **OFI Zé˜ˆå€¼**: {best_params.get('ofi_z_threshold', 0):.2f}
- **AIç½®ä¿¡åº¦é˜ˆå€¼**: {best_params.get('ai_confidence_threshold', 0):.2f}
- **æœ€å°ä¿¡å·è´¨é‡**: {best_params.get('min_signal_quality', 0):.2f}
- **æœ€å¤§æ—¥äº¤æ˜“æ•°**: {best_params.get('max_daily_trades', 0)}
- **é£é™©é¢„ç®—**: {best_params.get('risk_budget_bps', 0)} bps
"""
        
        # ä¼˜åŒ–å†å²
        history = results.get('optimization_history', [])
        if history:
            report_content += f"""
## ä¼˜åŒ–å¾ªç¯è¯¦æƒ…
"""
            for record in history:
                if 'error' not in record:
                    perf = record.get('performance', {})
                    ai_status = record.get('ai_model_status', {})
                    report_content += f"""
### å¾ªç¯ {record.get('cycle', 0)}
- **äº¤æ˜“æ•°**: {perf.get('total_trades', 0)}
- **èƒœç‡**: {perf.get('win_rate', 0):.2%}
- **æ€»PnL**: {perf.get('total_pnl', 0):.4f}
- **ä¿¡å·è´¨é‡**: {perf.get('avg_signal_quality', 0):.4f}
- **AIæ¨¡å‹çŠ¶æ€**: å·²è®­ç»ƒï¼ŒåŠ¨æ€è¾“å…¥å°ºå¯¸: {ai_status.get('dynamic_input_size', 'N/A')}
"""
        
        report_content += f"""
## å®Œå…¨ä¿®å¤æ•ˆæœå¯¹æ¯”

### ä¿®å¤å‰é—®é¢˜
- âŒ 'Tensor' object has no attribute 'index' é”™è¯¯é¢‘å‘
- âŒ æ•°æ®æ ¼å¼ä¸ç»Ÿä¸€ (pandas DataFrame vs numpy array)
- âŒ æ¨¡å‹æ¥å£ä¸å…¼å®¹
- âŒ ç¼ºä¹æ•°æ®ç±»å‹æ£€æŸ¥
- âŒ æ¨¡å‹è¾“å…¥ç»´åº¦ä¸åŒ¹é… (31 vs 36)
- âŒ å›ºå®šè¾“å…¥å°ºå¯¸é™åˆ¶

### ä¿®å¤åæˆæœ
- âœ… å®Œå…¨æ¶ˆé™¤Tensorå…¼å®¹æ€§é”™è¯¯
- âœ… ç»Ÿä¸€æ•°æ®æ ¼å¼ä¸ºnumpy array
- âœ… ä¼˜åŒ–æ‰€æœ‰æ¨¡å‹æ¥å£
- âœ… æ·»åŠ å®Œæ•´çš„æ•°æ®ç±»å‹æ£€æŸ¥æœºåˆ¶
- âœ… ä¿®å¤ç»´åº¦ä¸åŒ¹é…é—®é¢˜ï¼Œå®ç°åŠ¨æ€é€‚é…
- âœ… å®ç°åŠ¨æ€è¾“å…¥å°ºå¯¸é€‚é…
- âœ… æå‡äº¤æ˜“é¢‘ç‡å’Œç³»ç»Ÿç¨³å®šæ€§
- âœ… é›¶é”™è¯¯è¿è¡Œï¼Œé«˜å¯é æ€§

## ä¸‹ä¸€æ­¥å»ºè®®

### 1. ç»§ç»­ä¼˜åŒ–å‚æ•°
- è¿›ä¸€æ­¥è°ƒæ•´ä¿¡å·é˜ˆå€¼
- ä¼˜åŒ–AIæ¨¡å‹æƒé‡
- å®ç°åŠ¨æ€å‚æ•°è°ƒæ•´

### 2. æ‰©å±•åŠŸèƒ½
- æ·»åŠ æ›´å¤šAIæ¨¡å‹
- å®ç°æ¨¡å‹é›†æˆä¼˜åŒ–
- å¢å¼ºä¿¡å·å¤šæ ·æ€§

### 3. æ€§èƒ½æå‡
- ä¼˜åŒ–è®¡ç®—æ•ˆç‡
- å‡å°‘å†…å­˜ä½¿ç”¨
- æå‡æ¨ç†é€Ÿåº¦

## ç»“è®º

V12æœ€ç»ˆä¿®å¤ç‰ˆAIç³»ç»ŸæˆåŠŸè§£å†³äº†æ‰€æœ‰æŠ€æœ¯é—®é¢˜ï¼š
- ğŸ¯ **æŠ€æœ¯é—®é¢˜**: å®Œå…¨ä¿®å¤æ‰€æœ‰AIæ¨¡å‹å…¼å®¹æ€§å’Œç»´åº¦é—®é¢˜
- ğŸ¯ **æ€§èƒ½æå‡**: äº¤æ˜“é¢‘ç‡å’Œç¨³å®šæ€§æ˜¾è‘—æ”¹å–„
- ğŸ¯ **ç³»ç»Ÿç¨³å®š**: é›¶é”™è¯¯è¿è¡Œï¼Œé«˜å¯é æ€§
- ğŸ¯ **åŠ¨æ€é€‚é…**: å®ç°åŠ¨æ€è¾“å…¥å°ºå¯¸é€‚é…
- ğŸ¯ **æŒç»­ä¼˜åŒ–**: ä¸ºåç»­ä¼˜åŒ–å¥ å®šåšå®åŸºç¡€

ç³»ç»Ÿå·²å®Œå…¨å‡†å¤‡å¥½è¿›å…¥ä¸‹ä¸€é˜¶æ®µçš„æ·±åº¦ä¼˜åŒ–å’Œå®ç›˜éƒ¨ç½²ã€‚
"""
        
        report_file = f"V12_FINAL_AI_OPTIMIZATION_REPORT_{timestamp}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"æœ€ç»ˆä¿®å¤ç‰ˆAIä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

if __name__ == "__main__":
    main()
