#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 1.2 å…œåº•æ–¹æ¡ˆæµ‹è¯•è¿›åº¦ç›‘æ§è„šæœ¬
"""

import os
import sys
import time
import json
import pandas as pd
from pathlib import Path
import io

# Windows Unicode æ”¯æŒ
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def check_step_1_2_progress():
    """æ£€æŸ¥Step 1.2æµ‹è¯•è¿›åº¦"""
    
    # è¾“å‡ºç›®å½•
    output_dir = Path("../data/cvd_step_1_2_fallback_ethusdt")
    
    print("ğŸ” Step 1.2 å…œåº•æ–¹æ¡ˆæµ‹è¯•è¿›åº¦ç›‘æ§")
    print("=" * 60)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"â° æ£€æŸ¥æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not output_dir.exists():
        print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œæµ‹è¯•å¯èƒ½å°šæœªå¼€å§‹")
        return
    
    # æŸ¥æ‰¾æœ€æ–°çš„parquetæ–‡ä»¶
    parquet_files = list(output_dir.glob("*.parquet"))
    if not parquet_files:
        print("â³ å°šæœªç”Ÿæˆæ•°æ®æ–‡ä»¶ï¼Œæµ‹è¯•å¯èƒ½æ­£åœ¨å¯åŠ¨...")
        return
    
    latest_file = max(parquet_files, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“„ æœ€æ–°æ•°æ®æ–‡ä»¶: {latest_file.name}")
    
    # è¯»å–æ•°æ®
    try:
        df = pd.read_parquet(latest_file)
        print(f"ğŸ“Š æ•°æ®ç‚¹æ•°: {len(df):,}")
        
        # è®¡ç®—æ—¶é—´è·¨åº¦
        if 'timestamp' in df.columns and len(df) > 0:
            time_span = (df['timestamp'].max() - df['timestamp'].min()) / 1000
            print(f"â±ï¸  æ—¶é—´è·¨åº¦: {time_span:.1f} ç§’ ({time_span/60:.1f} åˆ†é’Ÿ)")
        
        # æ£€æŸ¥Z-scoreè´¨é‡
        if 'z_cvd' in df.columns:
            z_data = df['z_cvd'].dropna()
            if len(z_data) > 0:
                print(f"ğŸ“ˆ Z-scoreç»Ÿè®¡:")
                print(f"   - ä¸­ä½æ•°: {z_data.median():.6f}")
                print(f"   - median(|Z|): {z_data.abs().median():.6f}")
                print(f"   - P95(|Z|): {z_data.abs().quantile(0.95):.3f}")
                print(f"   - P99(|Z|): {z_data.abs().quantile(0.99):.3f}")
                
                # è®¡ç®—ç›®æ ‡æŒ‡æ ‡
                p_gt2 = (z_data.abs() > 2).mean() * 100
                p_gt3 = (z_data.abs() > 3).mean() * 100
                print(f"   - P(|Z|>2): {p_gt2:.2f}% (ç›®æ ‡: â‰¤8%)")
                print(f"   - P(|Z|>3): {p_gt3:.2f}% (ç›®æ ‡: â‰¤2%)")
                
                # çŠ¶æ€è¯„ä¼°
                print(f"\nğŸ¯ Step 1.2 ç›®æ ‡è¯„ä¼°:")
                median_ok = z_data.abs().median() <= 1.0
                p_gt2_ok = p_gt2 <= 8.0
                p_gt3_ok = p_gt3 <= 2.0
                
                print(f"   - median(|Z|) â‰¤ 1.0: {'âœ…' if median_ok else 'âŒ'}")
                print(f"   - P(|Z|>2) â‰¤ 8%: {'âœ…' if p_gt2_ok else 'âŒ'}")
                print(f"   - P(|Z|>3) â‰¤ 2%: {'âœ…' if p_gt3_ok else 'âŒ'}")
                
                if median_ok and p_gt2_ok and p_gt3_ok:
                    print(f"\nğŸ‰ Step 1.2 å…œåº•æ–¹æ¡ˆæˆåŠŸï¼æ‰€æœ‰ç›®æ ‡æŒ‡æ ‡è¾¾æ ‡ï¼")
                else:
                    print(f"\nâš ï¸  Step 1.2 å…œåº•æ–¹æ¡ˆéƒ¨åˆ†è¾¾æ ‡ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        if 'agg_dup_count' in df.columns:
            dup_count = df['agg_dup_count'].iloc[-1] if len(df) > 0 else 0
            backward_count = df['agg_backward_count'].iloc[-1] if len(df) > 0 else 0
            print(f"\nğŸ” æ•°æ®è´¨é‡:")
            print(f"   - aggTradeIdé‡å¤: {dup_count}")
            print(f"   - aggTradeIdå€’åº: {backward_count}")
        
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®æ—¶å‡ºé”™: {e}")
    
    print(f"\nâ° ä¸‹æ¬¡æ£€æŸ¥: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time() + 30))}")

if __name__ == "__main__":
    check_step_1_2_progress()
