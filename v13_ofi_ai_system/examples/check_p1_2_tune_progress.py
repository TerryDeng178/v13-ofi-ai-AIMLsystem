#!/usr/bin/env python3
"""
P1.2 Delta-Zå¾®è°ƒæµ‹è¯•è¿›åº¦ç›‘æ§è„šæœ¬
ç›‘æ§ETHUSDT 20åˆ†é’Ÿæµ‹è¯•çš„å®æ—¶è¿›åº¦
"""

import os
import sys
import time
import json
import io
from pathlib import Path

# Windows Unicodeå…¼å®¹æ€§
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def check_p1_2_tune_progress():
    """æ£€æŸ¥P1.2å¾®è°ƒæµ‹è¯•è¿›åº¦"""
    print("ğŸ” P1.2 Delta-Zå¾®è°ƒæµ‹è¯•è¿›åº¦ç›‘æ§")
    print("=" * 50)
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•
    output_dir = Path("../data/cvd_p1_2_ethusdt")
    if not output_dir.exists():
        print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œæµ‹è¯•å¯èƒ½å°šæœªå¼€å§‹")
        return
    
    # æŸ¥æ‰¾æœ€æ–°çš„parquetæ–‡ä»¶
    parquet_files = list(output_dir.glob("*.parquet"))
    if not parquet_files:
        print("â³ ç­‰å¾…æ•°æ®æ–‡ä»¶ç”Ÿæˆ...")
        return
    
    latest_file = max(parquet_files, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“ æœ€æ–°æ•°æ®æ–‡ä»¶: {latest_file.name}")
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°å’Œä¿®æ”¹æ—¶é—´
    file_size = latest_file.stat().st_size
    mod_time = latest_file.stat().st_mtime
    current_time = time.time()
    age_seconds = current_time - mod_time
    
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} bytes")
    print(f"â° æœ€åæ›´æ–°: {age_seconds:.1f} ç§’å‰")
    
    # å°è¯•è¯»å–parquetæ–‡ä»¶è·å–è®°å½•æ•°
    try:
        import pandas as pd
        df = pd.read_parquet(latest_file)
        record_count = len(df)
        print(f"ğŸ“ˆ å½“å‰è®°å½•æ•°: {record_count:,}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰Z-scoreæ•°æ®
        if 'z_cvd' in df.columns:
            z_data = df['z_cvd'].dropna()
            if len(z_data) > 0:
                median_z = abs(z_data).median()
                p_z_gt_2 = (abs(z_data) > 2).mean() * 100
                p_z_gt_3 = (abs(z_data) > 3).mean() * 100
                
                print(f"ğŸ¯ Z-scoreè´¨é‡:")
                print(f"   median(|Z|): {median_z:.4f}")
                print(f"   P(|Z|>2): {p_z_gt_2:.2f}%")
                print(f"   P(|Z|>3): {p_z_gt_3:.2f}%")
                
                # ç›®æ ‡æ£€æŸ¥
                print(f"ğŸ¯ ç›®æ ‡è¾¾æˆæƒ…å†µ:")
                print(f"   median(|Z|) â‰¤ 1.0: {'âœ…' if median_z <= 1.0 else 'âŒ'}")
                print(f"   P(|Z|>2) â‰¤ 10%: {'âœ…' if p_z_gt_2 <= 10.0 else 'âŒ'}")
                print(f"   P(|Z|>3) â‰¤ 2%: {'âœ…' if p_z_gt_3 <= 2.0 else 'âŒ'}")
        
        # æ£€æŸ¥æµ‹è¯•æ—¶é•¿
        if 'timestamp' in df.columns:
            time_span = (df['timestamp'].max() - df['timestamp'].min()) / 1000
            print(f"â±ï¸ æµ‹è¯•æ—¶é•¿: {time_span:.1f} ç§’ ({time_span/60:.1f} åˆ†é’Ÿ)")
            
            if time_span >= 1200:  # 20åˆ†é’Ÿ
                print("âœ… æµ‹è¯•æ—¶é•¿è¾¾æ ‡ (â‰¥20åˆ†é’Ÿ)")
            else:
                remaining = 1200 - time_span
                print(f"â³ è¿˜éœ€ {remaining:.1f} ç§’ ({remaining/60:.1f} åˆ†é’Ÿ)")
        
    except Exception as e:
        print(f"âš ï¸ è¯»å–æ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æŠ¥å‘Šæ–‡ä»¶
    report_files = list(output_dir.glob("*.json"))
    if report_files:
        latest_report = max(report_files, key=lambda x: x.stat().st_mtime)
        print(f"ğŸ“‹ æœ€æ–°æŠ¥å‘Š: {latest_report.name}")
        
        try:
            with open(latest_report, 'r', encoding='utf-8') as f:
                report_data = json.load(f)
            
            if 'final_metrics' in report_data:
                metrics = report_data['final_metrics']
                print(f"ğŸ“Š è¿è¡ŒæŒ‡æ ‡:")
                print(f"   æ€»æ¶ˆæ¯æ•°: {metrics.get('total_messages', 'N/A'):,}")
                print(f"   è§£æé”™è¯¯: {metrics.get('parse_errors', 'N/A')}")
                print(f"   é˜Ÿåˆ—ä¸¢å¼ƒ: {metrics.get('queue_dropped', 'N/A')}")
                print(f"   é‡è¿æ¬¡æ•°: {metrics.get('reconnect_count', 'N/A')}")
                
                if 'agg_dup_count' in metrics:
                    print(f"   é‡å¤ID: {metrics['agg_dup_count']}")
                    print(f"   å€’åºID: {metrics.get('agg_backward_count', 'N/A')}")
                    print(f"   å»¶è¿Ÿäº‹ä»¶: {metrics.get('late_event_dropped', 'N/A')}")
                    print(f"   ç¼“å†²P95: {metrics.get('buffer_size_p95', 'N/A')}")
                    print(f"   ç¼“å†²æœ€å¤§: {metrics.get('buffer_size_max', 'N/A')}")
        
        except Exception as e:
            print(f"âš ï¸ è¯»å–æŠ¥å‘Šæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    print("=" * 50)

if __name__ == "__main__":
    check_p1_2_tune_progress()
