#!/usr/bin/env python3
"""
æŒ‡æ ‡ä¾§å¯¹é½è„šæœ¬ - ç»Ÿä¸€PrometheusæŒ‡æ ‡å’ŒGrafanaé¢æ¿
ç¡®ä¿ç¦»çº¿è¯„ä¼°æŒ‡æ ‡ä¸åœ¨çº¿ç›‘æ§å£å¾„ä¸€è‡´
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, List, Any
import pandas as pd
import numpy as np
import yaml

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))


class MetricsAlignmentTool:
    """æŒ‡æ ‡å¯¹é½å·¥å…·"""
    
    def __init__(self, output_dir: str):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # PrometheusæŒ‡æ ‡å®šä¹‰
        self.prometheus_metrics = {
            'divergence_events_total': {
                'type': 'Counter',
                'help': 'Total number of divergence events detected',
                'labels': ['source', 'side', 'kind'],
                'description': 'äº‹ä»¶è®¡æ•°ï¼ˆCounterï¼‰'
            },
            'divergence_detection_latency_seconds': {
                'type': 'Histogram',
                'help': 'Time taken to detect divergence events',
                'labels': ['source'],
                'buckets': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0],
                'description': 'æ£€æµ‹å»¶è¿Ÿï¼ˆHistogramï¼‰'
            },
            'divergence_score_bucket': {
                'type': 'Histogram',
                'help': 'Distribution of divergence scores',
                'labels': ['source'],
                'buckets': [0, 20, 40, 60, 70, 80, 85, 90, 95, 100],
                'description': 'åˆ†æ•°åˆ†å¸ƒï¼ˆHistogramï¼Œå›ºå®šæ¡¶ï¼‰'
            },
            'divergence_pairing_gap_bars': {
                'type': 'Histogram',
                'help': 'Gap between pivot pairs in bars',
                'labels': ['source'],
                'buckets': [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000],
                'description': 'é…å¯¹é—´éš”ï¼ˆHistogramï¼‰'
            },
            'divergence_forward_return': {
                'type': 'Summary',
                'help': 'Forward returns after divergence events',
                'labels': ['horizon', 'source'],
                'description': 'å‰ç»æ”¶ç›Šï¼ˆSummary æˆ– Histogramï¼ŒHâˆˆ{10,20}ï¼‰'
            },
            'divergence_active_config_info': {
                'type': 'Info',
                'help': 'Current active configuration parameters',
                'labels': ['swing_L', 'z_hi', 'z_mid', 'version'],
                'description': 'ç”Ÿæ•ˆé…ç½®ï¼ˆInfo/Gaugeï¼‰'
            }
        }
        
        # Grafanaé¢æ¿å®šä¹‰
        self.grafana_panels = {
            'event_rate': {
                'title': 'äº‹ä»¶é€Ÿç‡',
                'query': 'rate(divergence_events_total[5m])',
                'description': 'åˆ† source/kind/side çš„äº‹ä»¶é€Ÿç‡'
            },
            'detection_latency_p95': {
                'title': 'æ£€æµ‹å»¶è¿Ÿ P95',
                'query': 'histogram_quantile(0.95, sum by (le,source)(rate(divergence_detection_latency_seconds_bucket[5m])))',
                'description': 'P95æ£€æµ‹å»¶è¿Ÿ'
            },
            'score_distribution': {
                'title': 'åˆ†æ•°åˆ†å¸ƒ',
                'query': 'divergence_score_bucket',
                'description': 'åˆ†æ•°åˆ†å¸ƒç›´æ–¹å›¾ + æ—¶é—´çƒ­åŠ›'
            },
            'forward_returns': {
                'title': 'å‰ç»æ”¶ç›Šåˆ†ç®±',
                'query': 'divergence_forward_return',
                'description': 'ç¦»çº¿äº§å‡ºçš„åˆ†ä½è¡¨å±•ç¤º'
            },
            'config_status': {
                'title': 'é…ç½®çŠ¶æ€',
                'query': 'divergence_active_config_info',
                'description': 'å½“å‰æ´»è·ƒå‚æ•°ä¸ç‰ˆæœ¬å·'
            }
        }
    
    def generate_prometheus_config(self):
        """ç”ŸæˆPrometheusé…ç½®"""
        prometheus_config = {
            'global': {
                'scrape_interval': '15s',
                'evaluation_interval': '15s'
            },
            'rule_files': [
                'alerting_rules/divergence_alerts.yaml'
            ],
            'scrape_configs': [
                {
                    'job_name': 'divergence-detector',
                    'static_configs': [
                        {
                            'targets': ['localhost:8003']
                        }
                    ],
                    'scrape_interval': '5s',
                    'metrics_path': '/metrics'
                }
            ]
        }
        
        # ä¿å­˜Prometheusé…ç½®
        prometheus_path = self.output_dir / "prometheus_divergence.yml"
        with open(prometheus_path, 'w', encoding='utf-8') as f:
            yaml.dump(prometheus_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"Prometheusé…ç½®å·²ä¿å­˜: {prometheus_path}")
    
    def generate_alerting_rules(self):
        """ç”Ÿæˆå‘Šè­¦è§„åˆ™"""
        alerting_rules = {
            'groups': [
                {
                    'name': 'divergence_detection',
                    'rules': [
                        {
                            'alert': 'DivergenceDetectionLatencyHigh',
                            'expr': 'histogram_quantile(0.95, rate(divergence_detection_latency_seconds_bucket[5m])) > 0.003',
                            'for': '1m',
                            'labels': {
                                'severity': 'warning'
                            },
                            'annotations': {
                                'summary': 'èƒŒç¦»æ£€æµ‹å»¶è¿Ÿè¿‡é«˜',
                                'description': 'P95æ£€æµ‹å»¶è¿Ÿè¶…è¿‡3ms: {{ $value }}s'
                            }
                        },
                        {
                            'alert': 'DivergenceEventsRateLow',
                            'expr': 'rate(divergence_events_total[1h]) < 0.1',
                            'for': '5m',
                            'labels': {
                                'severity': 'info'
                            },
                            'annotations': {
                                'summary': 'èƒŒç¦»äº‹ä»¶æ£€æµ‹ç‡è¿‡ä½',
                                'description': 'è¿‡å»1å°æ—¶äº‹ä»¶ç‡: {{ $value }}/s'
                            }
                        },
                        {
                            'alert': 'DivergenceScoreDistributionSkewed',
                            'expr': 'histogram_quantile(0.5, rate(divergence_score_bucket[1h])) < 50',
                            'for': '10m',
                            'labels': {
                                'severity': 'warning'
                            },
                            'annotations': {
                                'summary': 'èƒŒç¦»åˆ†æ•°åˆ†å¸ƒåæ–œ',
                                'description': 'ä¸­ä½æ•°åˆ†æ•°è¿‡ä½: {{ $value }}'
                            }
                        }
                    ]
                }
            ]
        }
        
        # ä¿å­˜å‘Šè­¦è§„åˆ™
        alerting_path = self.output_dir / "alerting_rules" / "divergence_alerts.yaml"
        alerting_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(alerting_path, 'w', encoding='utf-8') as f:
            yaml.dump(alerting_rules, f, default_flow_style=False, allow_unicode=True)
        
        print(f"å‘Šè­¦è§„åˆ™å·²ä¿å­˜: {alerting_path}")
    
    def generate_grafana_dashboard(self):
        """ç”ŸæˆGrafanaä»ªè¡¨ç›˜"""
        dashboard = {
            'dashboard': {
                'id': None,
                'title': 'èƒŒç¦»æ£€æµ‹ç›‘æ§é¢æ¿',
                'tags': ['divergence', 'trading', 'monitoring'],
                'timezone': 'browser',
                'panels': [],
                'time': {
                    'from': 'now-1h',
                    'to': 'now'
                },
                'refresh': '5s',
                'schemaVersion': 30,
                'version': 1,
                'uid': 'divergence-monitoring'
            }
        }
        
        # æ·»åŠ é¢æ¿
        panels = []
        
        # 1. äº‹ä»¶é€Ÿç‡é¢æ¿
        panels.append({
            'id': 1,
            'title': 'äº‹ä»¶é€Ÿç‡',
            'type': 'stat',
            'targets': [
                {
                    'expr': 'sum by (source) (rate(divergence_events_total[5m]))',
                    'legendFormat': '{{source}}'
                }
            ],
            'fieldConfig': {
                'defaults': {
                    'unit': 'short',
                    'thresholds': {
                        'steps': [
                            {'color': 'green', 'value': None},
                            {'color': 'yellow', 'value': 0.1},
                            {'color': 'red', 'value': 1.0}
                        ]
                    }
                }
            },
            'gridPos': {'h': 8, 'w': 12, 'x': 0, 'y': 0}
        })
        
        # 2. æ£€æµ‹å»¶è¿Ÿé¢æ¿
        panels.append({
            'id': 2,
            'title': 'æ£€æµ‹å»¶è¿Ÿ P95',
            'type': 'stat',
            'targets': [
                {
                    'expr': 'histogram_quantile(0.95, sum by (le,source)(rate(divergence_detection_latency_seconds_bucket[5m])))',
                    'legendFormat': '{{source}}'
                }
            ],
            'fieldConfig': {
                'defaults': {
                    'unit': 's',
                    'thresholds': {
                        'steps': [
                            {'color': 'green', 'value': None},
                            {'color': 'yellow', 'value': 0.002},
                            {'color': 'red', 'value': 0.003}
                        ]
                    }
                }
            },
            'gridPos': {'h': 8, 'w': 12, 'x': 12, 'y': 0}
        })
        
        # 3. åˆ†æ•°åˆ†å¸ƒé¢æ¿
        panels.append({
            'id': 3,
            'title': 'åˆ†æ•°åˆ†å¸ƒ',
            'type': 'heatmap',
            'targets': [
                {
                    'expr': 'sum by (le,source) (rate(divergence_score_bucket[5m]))',
                    'legendFormat': '{{source}}'
                }
            ],
            'gridPos': {'h': 8, 'w': 24, 'x': 0, 'y': 8}
        })
        
        # 4. å‰ç»æ”¶ç›Šé¢æ¿
        panels.append({
            'id': 4,
            'title': 'å‰ç»æ”¶ç›Š',
            'type': 'timeseries',
            'targets': [
                {
                    'expr': 'sum by (horizon,source) (rate(divergence_forward_return_sum[5m]) / rate(divergence_forward_return_count[5m]))',
                    'legendFormat': '{{source}} @{{horizon}}'
                }
            ],
            'gridPos': {'h': 8, 'w': 12, 'x': 0, 'y': 16}
        })
        
        # 5. é…ç½®çŠ¶æ€é¢æ¿
        panels.append({
            'id': 5,
            'title': 'é…ç½®çŠ¶æ€',
            'type': 'table',
            'targets': [
                {
                    'expr': 'divergence_active_config_info',
                    'format': 'table'
                }
            ],
            'gridPos': {'h': 8, 'w': 12, 'x': 12, 'y': 16}
        })
        
        dashboard['dashboard']['panels'] = panels
        
        # ä¿å­˜ä»ªè¡¨ç›˜
        dashboard_path = self.output_dir / "dashboards" / "divergence_overview.json"
        dashboard_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(dashboard_path, 'w', encoding='utf-8') as f:
            json.dump(dashboard, f, indent=2, ensure_ascii=False)
        
        print(f"Grafanaä»ªè¡¨ç›˜å·²ä¿å­˜: {dashboard_path}")
    
    def generate_metrics_exporter(self):
        """ç”ŸæˆæŒ‡æ ‡å¯¼å‡ºå™¨ä»£ç """
        exporter_code = '''#!/usr/bin/env python3
"""
èƒŒç¦»æ£€æµ‹PrometheusæŒ‡æ ‡å¯¼å‡ºå™¨
"""

import time
import sys
from pathlib import Path
from prometheus_client import Counter, Histogram, Summary, Info, start_http_server
import threading
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from src.ofi_cvd_divergence import DivergenceDetector, DivergenceConfig


class DivergenceMetricsExporter:
    """èƒŒç¦»æ£€æµ‹æŒ‡æ ‡å¯¼å‡ºå™¨"""
    
    def __init__(self, port: int = 8003):
        self.port = port
        
        # å®šä¹‰PrometheusæŒ‡æ ‡
        self.events_total = Counter(
            'divergence_events_total',
            'Total number of divergence events detected',
            ['source', 'side', 'kind']
        )
        
        self.detection_latency = Histogram(
            'divergence_detection_latency_seconds',
            'Time taken to detect divergence events',
            ['source'],
            buckets=[0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0]
        )
        
        self.score_bucket = Histogram(
            'divergence_score_bucket',
            'Distribution of divergence scores',
            ['source'],
            buckets=[0, 20, 40, 60, 70, 80, 85, 90, 95, 100]
        )
        
        self.pairing_gap = Histogram(
            'divergence_pairing_gap_bars',
            'Gap between pivot pairs in bars',
            ['source'],
            buckets=[1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]
        )
        
        self.forward_return = Summary(
            'divergence_forward_return',
            'Forward returns after divergence events',
            ['horizon', 'source']
        )
        
        self.config_info = Info(
            'divergence_active_config_info',
            'Current active configuration parameters'
        )
        
        # åˆ›å»ºæ£€æµ‹å™¨
        self.config = DivergenceConfig()
        self.detector = DivergenceDetector(self.config)
        
        # è®¾ç½®é…ç½®ä¿¡æ¯
        self.config_info.info({
            'swing_L': str(self.config.swing_L),
            'z_hi': str(self.config.z_hi),
            'z_mid': str(self.config.z_mid),
            'version': 'v1.0'
        })
    
    def start_server(self):
        """å¯åŠ¨PrometheusæœåŠ¡å™¨"""
        start_http_server(self.port)
        print(f"ğŸš€ PrometheusæŒ‡æ ‡æœåŠ¡å™¨å·²å¯åŠ¨: http://localhost:{self.port}/metrics")
    
    def simulate_events(self):
        """æ¨¡æ‹Ÿäº‹ä»¶ç”Ÿæˆï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        import random
        import numpy as np
        
        sources = ['OFI', 'CVD', 'FUSION']
        sides = ['bull', 'bear']
        kinds = ['regular', 'hidden']
        
        while True:
            # æ¨¡æ‹Ÿæ£€æµ‹å»¶è¿Ÿ
            start_time = time.time()
            
            # æ¨¡æ‹Ÿæ£€æµ‹è¿‡ç¨‹
            time.sleep(random.uniform(0.001, 0.005))
            
            # è®°å½•å»¶è¿Ÿ
            source = random.choice(sources)
            self.detection_latency.labels(source=source).observe(time.time() - start_time)
            
            # æ¨¡æ‹Ÿäº‹ä»¶ç”Ÿæˆ
            if random.random() < 0.1:  # 10%æ¦‚ç‡ç”Ÿæˆäº‹ä»¶
                side = random.choice(sides)
                kind = random.choice(kinds)
                score = random.uniform(0, 100)
                
                # è®°å½•äº‹ä»¶
                self.events_total.labels(
                    source=source,
                    side=side,
                    kind=kind
                ).inc()
                
                # è®°å½•åˆ†æ•°
                self.score_bucket.labels(source=source).observe(score)
                
                # è®°å½•é…å¯¹é—´éš”
                gap = random.randint(1, 100)
                self.pairing_gap.labels(source=source).observe(gap)
                
                # è®°å½•å‰ç»æ”¶ç›Š
                horizon = random.choice(['10', '20'])
                return_val = random.uniform(-0.05, 0.05)
                self.forward_return.labels(
                    horizon=horizon,
                    source=source
                ).observe(return_val)
            
            time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡


def main():
    exporter = DivergenceMetricsExporter()
    
    # å¯åŠ¨æœåŠ¡å™¨
    exporter.start_server()
    
    # å¯åŠ¨æ¨¡æ‹Ÿçº¿ç¨‹
    simulation_thread = threading.Thread(target=exporter.simulate_events)
    simulation_thread.daemon = True
    simulation_thread.start()
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\\nğŸ›‘ æŒ‡æ ‡å¯¼å‡ºå™¨å·²åœæ­¢")


if __name__ == "__main__":
    main()
'''
        
        # ä¿å­˜å¯¼å‡ºå™¨ä»£ç 
        exporter_path = self.output_dir / "divergence_metrics_exporter.py"
        with open(exporter_path, 'w', encoding='utf-8') as f:
            f.write(exporter_code)
        
        print(f"æŒ‡æ ‡å¯¼å‡ºå™¨å·²ä¿å­˜: {exporter_path}")
    
    def generate_alignment_check(self):
        """ç”Ÿæˆå¯¹é½æ£€æŸ¥è„šæœ¬"""
        check_script = '''#!/usr/bin/env python3
"""
æŒ‡æ ‡å¯¹é½æ£€æŸ¥è„šæœ¬
éªŒè¯ç¦»çº¿è¯„ä¼°æŒ‡æ ‡ä¸åœ¨çº¿ç›‘æ§å£å¾„ä¸€è‡´
"""

import requests
import json
import time
from pathlib import Path
from typing import Dict, Any


class MetricsAlignmentChecker:
    """æŒ‡æ ‡å¯¹é½æ£€æŸ¥å™¨"""
    
    def __init__(self, prometheus_url: str = "http://localhost:9090"):
        self.prometheus_url = prometheus_url
        self.results = {}
    
    def check_event_rate_alignment(self) -> Dict[str, Any]:
        """æ£€æŸ¥äº‹ä»¶é€Ÿç‡å¯¹é½"""
        try:
            # æŸ¥è¯¢åœ¨çº¿äº‹ä»¶é€Ÿç‡
            query = 'sum by (source) (rate(divergence_events_total[1h]))'
            response = requests.get(f"{self.prometheus_url}/api/v1/query", 
                                 params={'query': query})
            
            if response.status_code == 200:
                data = response.json()
                online_rates = {}
                for result in data['data']['result']:
                    source = result['metric'].get('source', 'unknown')
                    rate = float(result['value'][1])
                    online_rates[source] = rate
                
                # è¿™é‡Œåº”è¯¥ä¸ç¦»çº¿æ•°æ®å¯¹æ¯”
                # ç®€åŒ–ç‰ˆï¼šå‡è®¾ç¦»çº¿æ•°æ®
                offline_rates = {
                    'OFI': 0.5,
                    'CVD': 0.3,
                    'FUSION': 0.2
                }
                
                alignment_errors = {}
                for source in online_rates:
                    if source in offline_rates:
                        error_pct = abs(online_rates[source] - offline_rates[source]) / offline_rates[source] * 100
                        alignment_errors[source] = error_pct
                
                return {
                    'status': 'success',
                    'online_rates': online_rates,
                    'offline_rates': offline_rates,
                    'alignment_errors': alignment_errors,
                    'aligned': all(err < 10 for err in alignment_errors.values())
                }
            else:
                return {'status': 'error', 'message': f'HTTP {response.status_code}'}
                
        except Exception as e:
            return {'status': 'error', 'message': str(e)}
    
    def check_latency_threshold(self) -> Dict[str, Any]:
        """æ£€æŸ¥å»¶è¿Ÿé˜ˆå€¼"""
        try:
            query = 'histogram_quantile(0.95, sum by (le,source)(rate(divergence_detection_latency_seconds_bucket[5m])))'
            response = requests.get(f"{self.prometheus_url}/api/v1/query", 
                                 params={'query': query})
            
            if response.status_code == 200:
                data = response.json()
                max_latency = 0
                for result in data['data']['result']:
                    latency = float(result['value'][1])
                    max_latency = max(max_latency, latency)
                
                return {
                    'status': 'success',
                    'max_latency': max_latency,
                    'threshold': 0.003,
                    'passed': max_latency < 0.003
                }
            else:
                return {'status': 'error', 'message': f'HTTP {response.status_code}'}
                
        except Exception as e:
            return {'status': 'error', 'message': str(e)}
    
    def check_event_count_closure(self) -> Dict[str, Any]:
        """æ£€æŸ¥äº‹ä»¶è®¡æ•°é—­åˆ"""
        try:
            # æŸ¥è¯¢å„ç±»å‹äº‹ä»¶è®¡æ•°
            queries = {
                'bull': 'sum(rate(divergence_events_total{side="bull"}[1h]))',
                'bear': 'sum(rate(divergence_events_total{side="bear"}[1h]))',
                'regular': 'sum(rate(divergence_events_total{kind="regular"}[1h]))',
                'hidden': 'sum(rate(divergence_events_total{kind="hidden"}[1h]))',
                'total': 'sum(rate(divergence_events_total[1h]))'
            }
            
            results = {}
            for name, query in queries.items():
                response = requests.get(f"{self.prometheus_url}/api/v1/query", 
                                     params={'query': query})
                if response.status_code == 200:
                    data = response.json()
                    if data['data']['result']:
                        results[name] = float(data['data']['result'][0]['value'][1])
                    else:
                        results[name] = 0
                else:
                    results[name] = 0
            
            # æ£€æŸ¥é—­åˆæ€§
            bull_bear_sum = results.get('bull', 0) + results.get('bear', 0)
            regular_hidden_sum = results.get('regular', 0) + results.get('hidden', 0)
            total = results.get('total', 0)
            
            closure_checks = {
                'bull_bear_closure': abs(bull_bear_sum - total) / max(total, 1) < 0.1,
                'regular_hidden_closure': abs(regular_hidden_sum - total) / max(total, 1) < 0.1
            }
            
            return {
                'status': 'success',
                'counts': results,
                'closure_checks': closure_checks,
                'all_closed': all(closure_checks.values())
            }
            
        except Exception as e:
            return {'status': 'error', 'message': str(e)}
    
    def run_all_checks(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹æŒ‡æ ‡å¯¹é½æ£€æŸ¥...")
        
        checks = {
            'event_rate_alignment': self.check_event_rate_alignment(),
            'latency_threshold': self.check_latency_threshold(),
            'event_count_closure': self.check_event_count_closure()
        }
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'checks': checks,
            'overall_status': 'passed' if all(
                check.get('status') == 'success' and 
                (check.get('aligned', False) or check.get('passed', False) or check.get('all_closed', False))
                for check in checks.values()
            ) else 'failed'
        }
        
        return report


def main():
    checker = MetricsAlignmentChecker()
    report = checker.run_all_checks()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = Path("metrics_alignment_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“Š å¯¹é½æ£€æŸ¥æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    print(f"ğŸ¯ æ€»ä½“çŠ¶æ€: {report['overall_status']}")


if __name__ == "__main__":
    main()
'''
        
        # ä¿å­˜æ£€æŸ¥è„šæœ¬
        check_path = self.output_dir / "metrics_alignment_check.py"
        with open(check_path, 'w', encoding='utf-8') as f:
            f.write(check_script)
        
        print(f"å¯¹é½æ£€æŸ¥è„šæœ¬å·²ä¿å­˜: {check_path}")
    
    def generate_all(self):
        """ç”Ÿæˆæ‰€æœ‰é…ç½®å’Œè„šæœ¬"""
        print("å¼€å§‹ç”ŸæˆæŒ‡æ ‡å¯¹é½é…ç½®...")
        
        self.generate_prometheus_config()
        self.generate_alerting_rules()
        self.generate_grafana_dashboard()
        self.generate_metrics_exporter()
        self.generate_alignment_check()
        
        print("æŒ‡æ ‡å¯¹é½é…ç½®ç”Ÿæˆå®Œæˆ!")


def main():
    parser = argparse.ArgumentParser(description='æŒ‡æ ‡å¯¹é½å·¥å…·')
    parser.add_argument('--out', required=True, help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå·¥å…·
    tool = MetricsAlignmentTool(args.out)
    
    # ç”Ÿæˆæ‰€æœ‰é…ç½®
    tool.generate_all()


if __name__ == "__main__":
    main()
